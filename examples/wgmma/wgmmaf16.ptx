//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32688072
// Cuda compilation tools, release 12.1, V12.1.105
// Based on NVVM 7.0.1
//

.version 8.1
.target sm_90a
.address_size 64

	// .globl	_Z4testI6__halfS0_S0_EvPT_PT0_PT1_
// _ZZ4testI6__halfS0_S0_EvPT_PT0_PT1_E5smema has been demoted
// _ZZ4testI6__halfS0_S0_EvPT_PT0_PT1_E5smemb has been demoted

.visible .entry _Z4testI6__halfS0_S0_EvPT_PT0_PT1_(
	.param .u64 _Z4testI6__halfS0_S0_EvPT_PT0_PT1__param_0,
	.param .u64 _Z4testI6__halfS0_S0_EvPT_PT0_PT1__param_1,
	.param .u64 _Z4testI6__halfS0_S0_EvPT_PT0_PT1__param_2
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<69>;
	.reg .b32 	%r<251>;
	.reg .b64 	%rd<143>;
	// demoted variable
	.shared .align 4 .b8 _ZZ4testI6__halfS0_S0_EvPT_PT0_PT1_E5smema[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ4testI6__halfS0_S0_EvPT_PT0_PT1_E5smemb[8192];

	ld.param.u64 	%rd3, [_Z4testI6__halfS0_S0_EvPT_PT0_PT1__param_0];
	ld.param.u64 	%rd4, [_Z4testI6__halfS0_S0_EvPT_PT0_PT1__param_1];
	ld.param.u64 	%rd5, [_Z4testI6__halfS0_S0_EvPT_PT0_PT1__param_2];
	mov.u32 	%r1, %tid.x;
	setp.gt.s32 	%p1, %r1, 1023;
	@%p1 bra 	$L__BB0_3;

	mov.u32 	%r2, %ntid.x;
	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r9, _ZZ4testI6__halfS0_S0_EvPT_PT0_PT1_E5smema;
	mov.u32 	%r249, %r1;

$L__BB0_2:
	mul.wide.s32 	%rd6, %r249, 2;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.u16 	%rs1, [%rd7];
	shl.b32 	%r8, %r249, 1;
	add.s32 	%r10, %r9, %r8;
	st.shared.u16 	[%r10], %rs1;
	add.s32 	%r249, %r249, %r2;
	setp.lt.s32 	%p2, %r249, 1024;
	@%p2 bra 	$L__BB0_2;

$L__BB0_3:
	setp.gt.s32 	%p3, %r1, 2047;
	@%p3 bra 	$L__BB0_6;

	mov.u32 	%r5, %ntid.x;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r12, _ZZ4testI6__halfS0_S0_EvPT_PT0_PT1_E5smemb;
	mov.u32 	%r250, %r1;

$L__BB0_5:
	mul.wide.s32 	%rd8, %r250, 2;
	add.s64 	%rd9, %rd2, %rd8;
	ld.global.u16 	%rs2, [%rd9];
	shl.b32 	%r11, %r250, 1;
	add.s32 	%r13, %r12, %r11;
	st.shared.u16 	[%r13], %rs2;
	add.s32 	%r250, %r250, %r5;
	setp.lt.s32 	%p4, %r250, 2048;
	@%p4 bra 	$L__BB0_5;

$L__BB0_6:
	cvta.to.global.u64 	%rd12, %rd5;
	bar.sync 	0;
	mov.u32 	%r18, 0;
	// begin inline asm
	cvt.rn.f16.s32 %rs3, %r18;
	// end inline asm
	mov.u16 	%rs68, 0;
	mov.b32 	%r17, {%rs3, %rs68};
	// begin inline asm
	// end inline asm
	// begin inline asm
	wgmma.fence.sync.aligned;

	// end inline asm
	mov.u32 	%r148, _ZZ4testI6__halfS0_S0_EvPT_PT0_PT1_E5smema;
	shr.u32 	%r149, %r148, 4;
	and.b32  	%r150, %r149, 16383;
	cvt.u64.u32 	%rd13, %r150;
	or.b64  	%rd10, %rd13, 4611686293305360384;
	mov.u32 	%r151, _ZZ4testI6__halfS0_S0_EvPT_PT0_PT1_E5smemb;
	shr.u32 	%r152, %r151, 4;
	and.b32  	%r153, %r152, 16383;
	cvt.u64.u32 	%rd14, %r153;
	or.b64  	%rd11, %rd14, 4611686568187396096;
	mov.u32 	%r19, %r18;
	mov.u32 	%r20, %r18;
	mov.u32 	%r21, %r18;
	mov.u32 	%r22, %r18;
	mov.u32 	%r23, %r18;
	mov.u32 	%r24, %r18;
	mov.u32 	%r25, %r18;
	mov.u32 	%r26, %r18;
	mov.u32 	%r27, %r18;
	mov.u32 	%r28, %r18;
	mov.u32 	%r29, %r18;
	mov.u32 	%r30, %r18;
	mov.u32 	%r31, %r18;
	mov.u32 	%r32, %r18;
	mov.u32 	%r33, %r18;
	mov.u32 	%r34, %r18;
	mov.u32 	%r35, %r18;
	mov.u32 	%r36, %r18;
	mov.u32 	%r37, %r18;
	mov.u32 	%r38, %r18;
	mov.u32 	%r39, %r18;
	mov.u32 	%r40, %r18;
	mov.u32 	%r41, %r18;
	mov.u32 	%r42, %r18;
	mov.u32 	%r43, %r18;
	mov.u32 	%r44, %r18;
	mov.u32 	%r45, %r18;
	mov.u32 	%r46, %r18;
	mov.u32 	%r47, %r18;
	mov.u32 	%r48, %r18;
	// begin inline asm
	{
.reg .pred p;
setp.ne.b32 p, %r48, 0;
wgmma.mma_async.sync.aligned.m64n128k16.f16.f16.f16 {%r17,  %r18,  %r19,  %r20,  %r21,  %r22,  %r23,  %r24,   %r25,  %r26,  %r27, %r28, %r29, %r30, %r31, %r32,  %r33, %r34, %r35, %r36, %r37, %r38, %r39, %r40,  %r41, %r42, %r43, %r44, %r45, %r46, %r47, %r48}, %rd10, %rd11, p,   1, 1, 0, 1;
}

	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;

	// end inline asm
	// begin inline asm
	wgmma.wait_group.sync.aligned 0;

	// end inline asm
	// begin inline asm
	// end inline asm
	// begin inline asm
	cvt.rn.f16.u32 %rs4, %r17;
	// end inline asm
	mul.wide.u32 	%rd15, %r1, 2;
	add.s64 	%rd16, %rd12, %rd15;
	add.s32 	%r154, %r1, 128;
	st.global.u16 	[%rd16], %rs4;
	// begin inline asm
	cvt.rn.f16.u32 %rs5, %r18;
	// end inline asm
	mul.wide.u32 	%rd17, %r154, 2;
	add.s64 	%rd18, %rd12, %rd17;
	add.s32 	%r155, %r1, 256;
	st.global.u16 	[%rd18], %rs5;
	// begin inline asm
	cvt.rn.f16.u32 %rs6, %r19;
	// end inline asm
	mul.wide.u32 	%rd19, %r155, 2;
	add.s64 	%rd20, %rd12, %rd19;
	st.global.u16 	[%rd20], %rs6;
	add.s32 	%r156, %r1, 384;
	// begin inline asm
	cvt.rn.f16.u32 %rs7, %r20;
	// end inline asm
	mul.wide.u32 	%rd21, %r156, 2;
	add.s64 	%rd22, %rd12, %rd21;
	st.global.u16 	[%rd22], %rs7;
	add.s32 	%r157, %r1, 512;
	// begin inline asm
	cvt.rn.f16.u32 %rs8, %r21;
	// end inline asm
	mul.wide.u32 	%rd23, %r157, 2;
	add.s64 	%rd24, %rd12, %rd23;
	st.global.u16 	[%rd24], %rs8;
	add.s32 	%r158, %r1, 640;
	// begin inline asm
	cvt.rn.f16.u32 %rs9, %r22;
	// end inline asm
	mul.wide.u32 	%rd25, %r158, 2;
	add.s64 	%rd26, %rd12, %rd25;
	st.global.u16 	[%rd26], %rs9;
	add.s32 	%r159, %r1, 768;
	// begin inline asm
	cvt.rn.f16.u32 %rs10, %r23;
	// end inline asm
	mul.wide.u32 	%rd27, %r159, 2;
	add.s64 	%rd28, %rd12, %rd27;
	st.global.u16 	[%rd28], %rs10;
	add.s32 	%r160, %r1, 896;
	// begin inline asm
	cvt.rn.f16.u32 %rs11, %r24;
	// end inline asm
	mul.wide.u32 	%rd29, %r160, 2;
	add.s64 	%rd30, %rd12, %rd29;
	st.global.u16 	[%rd30], %rs11;
	add.s32 	%r161, %r1, 1024;
	// begin inline asm
	cvt.rn.f16.u32 %rs12, %r25;
	// end inline asm
	mul.wide.u32 	%rd31, %r161, 2;
	add.s64 	%rd32, %rd12, %rd31;
	st.global.u16 	[%rd32], %rs12;
	add.s32 	%r162, %r1, 1152;
	// begin inline asm
	cvt.rn.f16.u32 %rs13, %r26;
	// end inline asm
	mul.wide.u32 	%rd33, %r162, 2;
	add.s64 	%rd34, %rd12, %rd33;
	st.global.u16 	[%rd34], %rs13;
	add.s32 	%r163, %r1, 1280;
	// begin inline asm
	cvt.rn.f16.u32 %rs14, %r27;
	// end inline asm
	mul.wide.u32 	%rd35, %r163, 2;
	add.s64 	%rd36, %rd12, %rd35;
	st.global.u16 	[%rd36], %rs14;
	add.s32 	%r164, %r1, 1408;
	// begin inline asm
	cvt.rn.f16.u32 %rs15, %r28;
	// end inline asm
	mul.wide.u32 	%rd37, %r164, 2;
	add.s64 	%rd38, %rd12, %rd37;
	st.global.u16 	[%rd38], %rs15;
	add.s32 	%r165, %r1, 1536;
	// begin inline asm
	cvt.rn.f16.u32 %rs16, %r29;
	// end inline asm
	mul.wide.u32 	%rd39, %r165, 2;
	add.s64 	%rd40, %rd12, %rd39;
	st.global.u16 	[%rd40], %rs16;
	add.s32 	%r166, %r1, 1664;
	// begin inline asm
	cvt.rn.f16.u32 %rs17, %r30;
	// end inline asm
	mul.wide.u32 	%rd41, %r166, 2;
	add.s64 	%rd42, %rd12, %rd41;
	st.global.u16 	[%rd42], %rs17;
	add.s32 	%r167, %r1, 1792;
	// begin inline asm
	cvt.rn.f16.u32 %rs18, %r31;
	// end inline asm
	mul.wide.u32 	%rd43, %r167, 2;
	add.s64 	%rd44, %rd12, %rd43;
	st.global.u16 	[%rd44], %rs18;
	add.s32 	%r168, %r1, 1920;
	// begin inline asm
	cvt.rn.f16.u32 %rs19, %r32;
	// end inline asm
	mul.wide.u32 	%rd45, %r168, 2;
	add.s64 	%rd46, %rd12, %rd45;
	st.global.u16 	[%rd46], %rs19;
	add.s32 	%r169, %r1, 2048;
	// begin inline asm
	cvt.rn.f16.u32 %rs20, %r33;
	// end inline asm
	mul.wide.u32 	%rd47, %r169, 2;
	add.s64 	%rd48, %rd12, %rd47;
	st.global.u16 	[%rd48], %rs20;
	add.s32 	%r170, %r1, 2176;
	// begin inline asm
	cvt.rn.f16.u32 %rs21, %r34;
	// end inline asm
	mul.wide.u32 	%rd49, %r170, 2;
	add.s64 	%rd50, %rd12, %rd49;
	st.global.u16 	[%rd50], %rs21;
	add.s32 	%r171, %r1, 2304;
	// begin inline asm
	cvt.rn.f16.u32 %rs22, %r35;
	// end inline asm
	mul.wide.u32 	%rd51, %r171, 2;
	add.s64 	%rd52, %rd12, %rd51;
	st.global.u16 	[%rd52], %rs22;
	add.s32 	%r172, %r1, 2432;
	// begin inline asm
	cvt.rn.f16.u32 %rs23, %r36;
	// end inline asm
	mul.wide.u32 	%rd53, %r172, 2;
	add.s64 	%rd54, %rd12, %rd53;
	st.global.u16 	[%rd54], %rs23;
	add.s32 	%r173, %r1, 2560;
	// begin inline asm
	cvt.rn.f16.u32 %rs24, %r37;
	// end inline asm
	mul.wide.u32 	%rd55, %r173, 2;
	add.s64 	%rd56, %rd12, %rd55;
	st.global.u16 	[%rd56], %rs24;
	add.s32 	%r174, %r1, 2688;
	// begin inline asm
	cvt.rn.f16.u32 %rs25, %r38;
	// end inline asm
	mul.wide.u32 	%rd57, %r174, 2;
	add.s64 	%rd58, %rd12, %rd57;
	st.global.u16 	[%rd58], %rs25;
	add.s32 	%r175, %r1, 2816;
	// begin inline asm
	cvt.rn.f16.u32 %rs26, %r39;
	// end inline asm
	mul.wide.u32 	%rd59, %r175, 2;
	add.s64 	%rd60, %rd12, %rd59;
	st.global.u16 	[%rd60], %rs26;
	add.s32 	%r176, %r1, 2944;
	// begin inline asm
	cvt.rn.f16.u32 %rs27, %r40;
	// end inline asm
	mul.wide.u32 	%rd61, %r176, 2;
	add.s64 	%rd62, %rd12, %rd61;
	st.global.u16 	[%rd62], %rs27;
	add.s32 	%r177, %r1, 3072;
	// begin inline asm
	cvt.rn.f16.u32 %rs28, %r41;
	// end inline asm
	mul.wide.u32 	%rd63, %r177, 2;
	add.s64 	%rd64, %rd12, %rd63;
	st.global.u16 	[%rd64], %rs28;
	add.s32 	%r178, %r1, 3200;
	// begin inline asm
	cvt.rn.f16.u32 %rs29, %r42;
	// end inline asm
	mul.wide.u32 	%rd65, %r178, 2;
	add.s64 	%rd66, %rd12, %rd65;
	st.global.u16 	[%rd66], %rs29;
	add.s32 	%r179, %r1, 3328;
	// begin inline asm
	cvt.rn.f16.u32 %rs30, %r43;
	// end inline asm
	mul.wide.u32 	%rd67, %r179, 2;
	add.s64 	%rd68, %rd12, %rd67;
	st.global.u16 	[%rd68], %rs30;
	add.s32 	%r180, %r1, 3456;
	// begin inline asm
	cvt.rn.f16.u32 %rs31, %r44;
	// end inline asm
	mul.wide.u32 	%rd69, %r180, 2;
	add.s64 	%rd70, %rd12, %rd69;
	st.global.u16 	[%rd70], %rs31;
	add.s32 	%r181, %r1, 3584;
	// begin inline asm
	cvt.rn.f16.u32 %rs32, %r45;
	// end inline asm
	mul.wide.u32 	%rd71, %r181, 2;
	add.s64 	%rd72, %rd12, %rd71;
	st.global.u16 	[%rd72], %rs32;
	add.s32 	%r182, %r1, 3712;
	// begin inline asm
	cvt.rn.f16.u32 %rs33, %r46;
	// end inline asm
	mul.wide.u32 	%rd73, %r182, 2;
	add.s64 	%rd74, %rd12, %rd73;
	st.global.u16 	[%rd74], %rs33;
	add.s32 	%r183, %r1, 3840;
	// begin inline asm
	cvt.rn.f16.u32 %rs34, %r47;
	// end inline asm
	mul.wide.u32 	%rd75, %r183, 2;
	add.s64 	%rd76, %rd12, %rd75;
	st.global.u16 	[%rd76], %rs34;
	add.s32 	%r184, %r1, 3968;
	// begin inline asm
	cvt.rn.f16.u32 %rs35, %r48;
	// end inline asm
	mul.wide.u32 	%rd77, %r184, 2;
	add.s64 	%rd78, %rd12, %rd77;
	st.global.u16 	[%rd78], %rs35;
	add.s32 	%r185, %r1, 4096;
	// begin inline asm
	cvt.rn.f16.u32 %rs36, %r186;
	// end inline asm
	mul.wide.u32 	%rd79, %r185, 2;
	add.s64 	%rd80, %rd12, %rd79;
	st.global.u16 	[%rd80], %rs36;
	add.s32 	%r187, %r1, 4224;
	// begin inline asm
	cvt.rn.f16.u32 %rs37, %r188;
	// end inline asm
	mul.wide.u32 	%rd81, %r187, 2;
	add.s64 	%rd82, %rd12, %rd81;
	st.global.u16 	[%rd82], %rs37;
	add.s32 	%r189, %r1, 4352;
	// begin inline asm
	cvt.rn.f16.u32 %rs38, %r190;
	// end inline asm
	mul.wide.u32 	%rd83, %r189, 2;
	add.s64 	%rd84, %rd12, %rd83;
	st.global.u16 	[%rd84], %rs38;
	add.s32 	%r191, %r1, 4480;
	// begin inline asm
	cvt.rn.f16.u32 %rs39, %r192;
	// end inline asm
	mul.wide.u32 	%rd85, %r191, 2;
	add.s64 	%rd86, %rd12, %rd85;
	st.global.u16 	[%rd86], %rs39;
	add.s32 	%r193, %r1, 4608;
	// begin inline asm
	cvt.rn.f16.u32 %rs40, %r194;
	// end inline asm
	mul.wide.u32 	%rd87, %r193, 2;
	add.s64 	%rd88, %rd12, %rd87;
	st.global.u16 	[%rd88], %rs40;
	add.s32 	%r195, %r1, 4736;
	// begin inline asm
	cvt.rn.f16.u32 %rs41, %r196;
	// end inline asm
	mul.wide.u32 	%rd89, %r195, 2;
	add.s64 	%rd90, %rd12, %rd89;
	st.global.u16 	[%rd90], %rs41;
	add.s32 	%r197, %r1, 4864;
	// begin inline asm
	cvt.rn.f16.u32 %rs42, %r198;
	// end inline asm
	mul.wide.u32 	%rd91, %r197, 2;
	add.s64 	%rd92, %rd12, %rd91;
	st.global.u16 	[%rd92], %rs42;
	add.s32 	%r199, %r1, 4992;
	// begin inline asm
	cvt.rn.f16.u32 %rs43, %r200;
	// end inline asm
	mul.wide.u32 	%rd93, %r199, 2;
	add.s64 	%rd94, %rd12, %rd93;
	st.global.u16 	[%rd94], %rs43;
	add.s32 	%r201, %r1, 5120;
	// begin inline asm
	cvt.rn.f16.u32 %rs44, %r202;
	// end inline asm
	mul.wide.u32 	%rd95, %r201, 2;
	add.s64 	%rd96, %rd12, %rd95;
	st.global.u16 	[%rd96], %rs44;
	add.s32 	%r203, %r1, 5248;
	// begin inline asm
	cvt.rn.f16.u32 %rs45, %r204;
	// end inline asm
	mul.wide.u32 	%rd97, %r203, 2;
	add.s64 	%rd98, %rd12, %rd97;
	st.global.u16 	[%rd98], %rs45;
	add.s32 	%r205, %r1, 5376;
	// begin inline asm
	cvt.rn.f16.u32 %rs46, %r206;
	// end inline asm
	mul.wide.u32 	%rd99, %r205, 2;
	add.s64 	%rd100, %rd12, %rd99;
	st.global.u16 	[%rd100], %rs46;
	add.s32 	%r207, %r1, 5504;
	// begin inline asm
	cvt.rn.f16.u32 %rs47, %r208;
	// end inline asm
	mul.wide.u32 	%rd101, %r207, 2;
	add.s64 	%rd102, %rd12, %rd101;
	st.global.u16 	[%rd102], %rs47;
	add.s32 	%r209, %r1, 5632;
	// begin inline asm
	cvt.rn.f16.u32 %rs48, %r210;
	// end inline asm
	mul.wide.u32 	%rd103, %r209, 2;
	add.s64 	%rd104, %rd12, %rd103;
	st.global.u16 	[%rd104], %rs48;
	add.s32 	%r211, %r1, 5760;
	// begin inline asm
	cvt.rn.f16.u32 %rs49, %r212;
	// end inline asm
	mul.wide.u32 	%rd105, %r211, 2;
	add.s64 	%rd106, %rd12, %rd105;
	st.global.u16 	[%rd106], %rs49;
	add.s32 	%r213, %r1, 5888;
	// begin inline asm
	cvt.rn.f16.u32 %rs50, %r214;
	// end inline asm
	mul.wide.u32 	%rd107, %r213, 2;
	add.s64 	%rd108, %rd12, %rd107;
	st.global.u16 	[%rd108], %rs50;
	add.s32 	%r215, %r1, 6016;
	// begin inline asm
	cvt.rn.f16.u32 %rs51, %r216;
	// end inline asm
	mul.wide.u32 	%rd109, %r215, 2;
	add.s64 	%rd110, %rd12, %rd109;
	st.global.u16 	[%rd110], %rs51;
	add.s32 	%r217, %r1, 6144;
	// begin inline asm
	cvt.rn.f16.u32 %rs52, %r218;
	// end inline asm
	mul.wide.u32 	%rd111, %r217, 2;
	add.s64 	%rd112, %rd12, %rd111;
	st.global.u16 	[%rd112], %rs52;
	add.s32 	%r219, %r1, 6272;
	// begin inline asm
	cvt.rn.f16.u32 %rs53, %r220;
	// end inline asm
	mul.wide.u32 	%rd113, %r219, 2;
	add.s64 	%rd114, %rd12, %rd113;
	st.global.u16 	[%rd114], %rs53;
	add.s32 	%r221, %r1, 6400;
	// begin inline asm
	cvt.rn.f16.u32 %rs54, %r222;
	// end inline asm
	mul.wide.u32 	%rd115, %r221, 2;
	add.s64 	%rd116, %rd12, %rd115;
	st.global.u16 	[%rd116], %rs54;
	add.s32 	%r223, %r1, 6528;
	// begin inline asm
	cvt.rn.f16.u32 %rs55, %r224;
	// end inline asm
	mul.wide.u32 	%rd117, %r223, 2;
	add.s64 	%rd118, %rd12, %rd117;
	st.global.u16 	[%rd118], %rs55;
	add.s32 	%r225, %r1, 6656;
	// begin inline asm
	cvt.rn.f16.u32 %rs56, %r226;
	// end inline asm
	mul.wide.u32 	%rd119, %r225, 2;
	add.s64 	%rd120, %rd12, %rd119;
	st.global.u16 	[%rd120], %rs56;
	add.s32 	%r227, %r1, 6784;
	// begin inline asm
	cvt.rn.f16.u32 %rs57, %r228;
	// end inline asm
	mul.wide.u32 	%rd121, %r227, 2;
	add.s64 	%rd122, %rd12, %rd121;
	st.global.u16 	[%rd122], %rs57;
	add.s32 	%r229, %r1, 6912;
	// begin inline asm
	cvt.rn.f16.u32 %rs58, %r230;
	// end inline asm
	mul.wide.u32 	%rd123, %r229, 2;
	add.s64 	%rd124, %rd12, %rd123;
	st.global.u16 	[%rd124], %rs58;
	add.s32 	%r231, %r1, 7040;
	// begin inline asm
	cvt.rn.f16.u32 %rs59, %r232;
	// end inline asm
	mul.wide.u32 	%rd125, %r231, 2;
	add.s64 	%rd126, %rd12, %rd125;
	st.global.u16 	[%rd126], %rs59;
	add.s32 	%r233, %r1, 7168;
	// begin inline asm
	cvt.rn.f16.u32 %rs60, %r234;
	// end inline asm
	mul.wide.u32 	%rd127, %r233, 2;
	add.s64 	%rd128, %rd12, %rd127;
	st.global.u16 	[%rd128], %rs60;
	add.s32 	%r235, %r1, 7296;
	// begin inline asm
	cvt.rn.f16.u32 %rs61, %r236;
	// end inline asm
	mul.wide.u32 	%rd129, %r235, 2;
	add.s64 	%rd130, %rd12, %rd129;
	st.global.u16 	[%rd130], %rs61;
	add.s32 	%r237, %r1, 7424;
	// begin inline asm
	cvt.rn.f16.u32 %rs62, %r238;
	// end inline asm
	mul.wide.u32 	%rd131, %r237, 2;
	add.s64 	%rd132, %rd12, %rd131;
	st.global.u16 	[%rd132], %rs62;
	add.s32 	%r239, %r1, 7552;
	// begin inline asm
	cvt.rn.f16.u32 %rs63, %r240;
	// end inline asm
	mul.wide.u32 	%rd133, %r239, 2;
	add.s64 	%rd134, %rd12, %rd133;
	st.global.u16 	[%rd134], %rs63;
	add.s32 	%r241, %r1, 7680;
	// begin inline asm
	cvt.rn.f16.u32 %rs64, %r242;
	// end inline asm
	mul.wide.u32 	%rd135, %r241, 2;
	add.s64 	%rd136, %rd12, %rd135;
	st.global.u16 	[%rd136], %rs64;
	add.s32 	%r243, %r1, 7808;
	// begin inline asm
	cvt.rn.f16.u32 %rs65, %r244;
	// end inline asm
	mul.wide.u32 	%rd137, %r243, 2;
	add.s64 	%rd138, %rd12, %rd137;
	st.global.u16 	[%rd138], %rs65;
	add.s32 	%r245, %r1, 7936;
	// begin inline asm
	cvt.rn.f16.u32 %rs66, %r246;
	// end inline asm
	mul.wide.u32 	%rd139, %r245, 2;
	add.s64 	%rd140, %rd12, %rd139;
	st.global.u16 	[%rd140], %rs66;
	add.s32 	%r247, %r1, 8064;
	// begin inline asm
	cvt.rn.f16.u32 %rs67, %r248;
	// end inline asm
	mul.wide.u32 	%rd141, %r247, 2;
	add.s64 	%rd142, %rd12, %rd141;
	st.global.u16 	[%rd142], %rs67;
	ret;

}
	// .globl	_Z9referenceI6__halfS0_S0_EvPT_PT0_PT1_
.visible .entry _Z9referenceI6__halfS0_S0_EvPT_PT0_PT1_(
	.param .u64 _Z9referenceI6__halfS0_S0_EvPT_PT0_PT1__param_0,
	.param .u64 _Z9referenceI6__halfS0_S0_EvPT_PT0_PT1__param_1,
	.param .u64 _Z9referenceI6__halfS0_S0_EvPT_PT0_PT1__param_2
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<97>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd5, [_Z9referenceI6__halfS0_S0_EvPT_PT0_PT1__param_0];
	ld.param.u64 	%rd6, [_Z9referenceI6__halfS0_S0_EvPT_PT0_PT1__param_1];
	ld.param.u64 	%rd7, [_Z9referenceI6__halfS0_S0_EvPT_PT0_PT1__param_2];
	cvta.to.global.u64 	%rd1, %rd7;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r11, 0;
	mov.u32 	%r2, %ntid.x;

$L__BB1_1:
	setp.gt.s32 	%p1, %r1, 127;
	@%p1 bra 	$L__BB1_4;

	shl.b32 	%r9, %r11, 4;
	shl.b32 	%r4, %r11, 7;
	mul.wide.s32 	%rd8, %r9, 2;
	add.s64 	%rd4, %rd3, %rd8;
	mov.u32 	%r12, %r1;

$L__BB1_3:
	add.s32 	%r10, %r12, %r4;
	mul.wide.s32 	%rd9, %r10, 2;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.u16 	%rs2, [%rd4];
	mul.wide.s32 	%rd11, %r12, 2;
	add.s64 	%rd12, %rd2, %rd11;
	ld.global.u16 	%rs3, [%rd12];
	// begin inline asm
	{mul.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	ld.global.u16 	%rs5, [%rd10];
	// begin inline asm
	{add.f16 %rs4,%rs5,%rs1;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs4;
	ld.global.u16 	%rs8, [%rd4+2];
	ld.global.u16 	%rs9, [%rd12+256];
	// begin inline asm
	{mul.f16 %rs7,%rs8,%rs9;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs10,%rs4,%rs7;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs10;
	ld.global.u16 	%rs14, [%rd4+4];
	ld.global.u16 	%rs15, [%rd12+512];
	// begin inline asm
	{mul.f16 %rs13,%rs14,%rs15;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs16,%rs10,%rs13;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs16;
	ld.global.u16 	%rs20, [%rd4+6];
	ld.global.u16 	%rs21, [%rd12+768];
	// begin inline asm
	{mul.f16 %rs19,%rs20,%rs21;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs22,%rs16,%rs19;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs22;
	ld.global.u16 	%rs26, [%rd4+8];
	ld.global.u16 	%rs27, [%rd12+1024];
	// begin inline asm
	{mul.f16 %rs25,%rs26,%rs27;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs28,%rs22,%rs25;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs28;
	ld.global.u16 	%rs32, [%rd4+10];
	ld.global.u16 	%rs33, [%rd12+1280];
	// begin inline asm
	{mul.f16 %rs31,%rs32,%rs33;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs34,%rs28,%rs31;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs34;
	ld.global.u16 	%rs38, [%rd4+12];
	ld.global.u16 	%rs39, [%rd12+1536];
	// begin inline asm
	{mul.f16 %rs37,%rs38,%rs39;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs40,%rs34,%rs37;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs40;
	ld.global.u16 	%rs44, [%rd4+14];
	ld.global.u16 	%rs45, [%rd12+1792];
	// begin inline asm
	{mul.f16 %rs43,%rs44,%rs45;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs46,%rs40,%rs43;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs46;
	ld.global.u16 	%rs50, [%rd4+16];
	ld.global.u16 	%rs51, [%rd12+2048];
	// begin inline asm
	{mul.f16 %rs49,%rs50,%rs51;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs52,%rs46,%rs49;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs52;
	ld.global.u16 	%rs56, [%rd4+18];
	ld.global.u16 	%rs57, [%rd12+2304];
	// begin inline asm
	{mul.f16 %rs55,%rs56,%rs57;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs58,%rs52,%rs55;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs58;
	ld.global.u16 	%rs62, [%rd4+20];
	ld.global.u16 	%rs63, [%rd12+2560];
	// begin inline asm
	{mul.f16 %rs61,%rs62,%rs63;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs64,%rs58,%rs61;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs64;
	ld.global.u16 	%rs68, [%rd4+22];
	ld.global.u16 	%rs69, [%rd12+2816];
	// begin inline asm
	{mul.f16 %rs67,%rs68,%rs69;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs70,%rs64,%rs67;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs70;
	ld.global.u16 	%rs74, [%rd4+24];
	ld.global.u16 	%rs75, [%rd12+3072];
	// begin inline asm
	{mul.f16 %rs73,%rs74,%rs75;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs76,%rs70,%rs73;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs76;
	ld.global.u16 	%rs80, [%rd4+26];
	ld.global.u16 	%rs81, [%rd12+3328];
	// begin inline asm
	{mul.f16 %rs79,%rs80,%rs81;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs82,%rs76,%rs79;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs82;
	ld.global.u16 	%rs86, [%rd4+28];
	ld.global.u16 	%rs87, [%rd12+3584];
	// begin inline asm
	{mul.f16 %rs85,%rs86,%rs87;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs88,%rs82,%rs85;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs88;
	ld.global.u16 	%rs92, [%rd4+30];
	ld.global.u16 	%rs93, [%rd12+3840];
	// begin inline asm
	{mul.f16 %rs91,%rs92,%rs93;
}
	// end inline asm
	// begin inline asm
	{add.f16 %rs94,%rs88,%rs91;
}
	// end inline asm
	st.global.u16 	[%rd10], %rs94;
	add.s32 	%r12, %r12, %r2;
	setp.lt.s32 	%p2, %r12, 128;
	@%p2 bra 	$L__BB1_3;

$L__BB1_4:
	add.s32 	%r11, %r11, 1;
	setp.lt.u32 	%p3, %r11, 64;
	@%p3 bra 	$L__BB1_1;

	ret;

}

